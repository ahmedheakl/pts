# Model identifiers can be HF model ids or internal checkpoints.
diffusion:
  model_id: "Dream-org/Dream-v0-Instruct-7B" 
  device: "cuda:0"      # or "cpu"
  max_new_tokens: 256

llm:
  model_id: "Qwen/Qwen2.5-3B-Instruct"  #"Qwen/Qwen2.5-7B-Instruct
  device: "cuda:0"
  max_new_tokens: 512
  temperature: 0
  do_sample: false

llm_gpt:
  model_id: "gpt-4o"
  max_new_tokens: 512
  temperature:  0
  do_sample: false

runtime:
  output_dir: "outputs"
  json_prefix: "run"
  seed: 42

prompting:
  # Template for the *final* LLM call that takes concatenated input
  final_system_msg: ""
  concat_header_plan: "## PLAN"
  concat_header_refined: "## REFINED PLAN"
  concat_header_extra: "## LLM Instructions"
